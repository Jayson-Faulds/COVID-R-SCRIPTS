# when looking at the random component of the decomposition of a time series, often times consecutive variables are correlated
# if we can identify such correlations, we can use them to make our forecasts better

# mean function of a time series model: mu(t) = E(xt)
# the expectation is an average of all possible time series that might have been produced by the time series model
# with historical data, we usually only have one single time series
# so we estimate the observed values as the mean for that time t, after decomposing and removing seasonal/trend effects
# if the mean function is constant, the time series is stationary in the mean
# sample mean: sum(xt)/n, where n is the number of periods in the time series
# usually we need a decently large n; models with decently large n are called ergodic

# variance of a time series stationary in the mean: var(t) = E[(xt - mu)^2]
# technically this can be different for each time t, but we assume a constant variance sigma^2 
# thus, we assume models are stationary in variance: sum(xt - xbar)^2/(n - 1)

# second-order stationary: when a model stationary in the mean and variance has correlations between its variables,
# but the correlation only depends on the number of time periods separating them
# number of time periods/steps is called the lag
# a correlation of a variable with itself at different time periods is called an autocorrelation
# if second-order stationary is achieved, we can define an autocovariance function (acvf) as a function of a lag k
# yk = E[(xt - mu)(x(t + k) - mu)],    where (t + k) is a subsctipt; notice how this is a version of the covariance function
# here mu is the mean for both xt and x(t + k)
# because the expected value is across the ensemble, it will be the same at all times t; meaning yk only depends on k
# lag k autocorrelation function: pk = yk/sigma^2
# when k = 0, yk is equal to sigma^2, making pk = 1
# when we generate estimates for acf, it will fall between -1 and 1

wave.dat <- read.table('http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/wave.dat', header = TRUE)
plot(ts(wave.dat$waveht)) # no outlying values, and we know from beforehand that there is no trend or seasonal period
                          # we can thus assume a stationary time series
plot(ts(wave.dat$waveht[1:60])) # there is a tendency for consecutive values to be relatively similar
                                # the form is like a sea with a period-like structure but no fixed frequency
acf(wave.dat$waveht)$acf[2] # autocorrelation for lag 1 is 0.47 (you can see it in the chart too)
plot(wave.dat$waveht[1:396], wave.dat$waveht[2:397]) # plot an autocorrelation for lag 1
acf(wave.dat$waveht, type = c('covariance'))$acf[2]  # does the autocovariance instead of autocorrelation

# the plot generated by acf() is called a correlogram, which plots pk against k
# x-axis is lag, and y-axis is autocorrelation, where lag is the sampling interval or step between time periods
# the blue dotted lines represent a 95% confidence interval, meaning any points beyond the band are evidence against
# the null hypothesis that autocorrelation = 0 at the 5% level
# for a monthly series, a significant autocorrelation at lag 12 might indicate that our seasonal adjustment is not adequate
# notice how lag 0 is always 1
# statistical significance does not always indicate practical significance as well
# usually a trend in the data will show in the correlogram as a slow decay in the autocorrelations, which begin large and positive
acf(AirPassengers)

# if there is seasonal variation, seasonal spikes will appear in the correlogram systematically
# notice the peak in the chart at 1 year; seems there's like a seasonal peak around that time
# although we can notice these things, the main point of a correlogram is to detect autocorrelation after
# we have removed our estimate of the trend and seasonal variation
AP <- AirPassengers
AP.decom <- decompose(AP, 'multiplicative')
plot(ts(AP.decom$random[7:138])) # because our central moving average is 12 months, the first and last 6 time periods cannot be calculated
acf(AP.decom$random[7:138]) # we see a somewhat cosine-like shape despite accounting for seasonal variation with decompose()
sd(AP[7:138])
sd(AP[7:138] - AP.decom$trend[7:138])
sd(AP.decom$random[7:138]) # the declining of the standard deviation shows that our seasonal adjustment was indeed effective
# that means the actual autocorrelation structure resembles a cosine function, which indicates a special type of time series

Fontdsdt.dat <- read.table('http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/Fontdsdt.dat', header = TRUE)
attach(Fontdsdt.dat)
plot(ts(adflow), ylab = 'adflow')
acf(adflow, xlab = 'lag (months)', main = '') # statistically significant correlation at lag 1

################################## Exercises ##########################################

### 2

## a

# read in data
serendipity <- c(39, 35, 16, 18, 7, 22, 13, 18, 20, 9, -12, -11, -19, -9, -2, 16)
cagey <- c(47, -26, 42, -10, 27, -8, 16, 6, -1, 25, 11, 1, 25, 7, -5, 3)

# time plots
plot(ts(serendipity))
plot(ts(cagey))

## b

# lag 1 scatter plots
plot(serendipity[1:15], serendipity[2:16])
plot(cagey[1:15], cagey[2:16])

## c

# acf
acf(serendipity) # autocorrelation seems to be cyclic
acf(cagey) # flip flops for lags 1:2 but seeems to settle after

### 3

## a

# read in data
temp <- scan('http://www.maths.adelaide.edu.au/andrew.metcalfe/Data/global.dat')

# decompose time series
temp_ts <- ts(temp, st = c(1856, 1), end = c(2005, 12), fr = 12)
temp_decom <- decompose(temp_ts)
plot(temp_decom)

# compare sd of original series vs. deseasonalized
sd(temp_ts[7:1794]) # we start at 7 because of the moving average
sd(temp_decom$random[7:1794]) # sd went down, suggesting our seasonal adjustment is working

# plot of trend with seasonal effect
ts.plot(cbind(temp_decom$trend, temp_decom$trend + temp_decom$seasonal), lty = 1:2) # we add the effect bc it is additive

## b

# correlogram of the residuals
acf(temp_decom$random[7:1794]) # seems to be a cyclic pattern for the lagged correlations












